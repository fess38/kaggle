{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "kviks2l4hc3eyt87l6nfb"
   },
   "source": [
    "### Prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "okba3s2j2ka81pejlmxh1o"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "mkdir -p ../input\n",
    "mkdir -p ../output\n",
    "cd ../input\n",
    "\n",
    "export KAGGLE_USERNAME=\"fess38\"\n",
    "export KAGGLE_KEY=\"071966146ec1ebef62023a5efa0574b1\"\n",
    "kaggle competitions download -c jane-street-market-prediction\n",
    "\n",
    "unzip jane-street-market-prediction.zip\n",
    "rm jane-street-market-prediction.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xm2d1ukqreky9p0d2g04fp"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gyc0u5edjuizta8vsl8hvp",
    "execution_id": "9e442bba-f145-4cea-afdd-a772355bb1b4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "o37qnzj77wrdfxqvc6e1jv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import sum_models, CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, TimeSeriesSplit\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "z4g07mdqgheyzvtpn92a5g"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "mpl.rcParams[\"figure.figsize\"] = (11, 5)\n",
    "mpl.rcParams[\"figure.dpi\"]= 100\n",
    "mpl.rcParams[\"lines.linewidth\"] = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2l168l4ogre8w2j8m5wc49"
   },
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tt1yhlytdrwu42ypeukol"
   },
   "outputs": [],
   "source": [
    "input_data_path = \"../input/\"\n",
    "output_data_path = \"../output/\"\n",
    "features = [\"feature_\" + str(i) for i in range(130)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qywtctpvhzkeomdx3why4o"
   },
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    #tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    pass\n",
    "\n",
    "random_state = 42\n",
    "seed_all(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "52jqd6zjwdp25uc2uakva2"
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1skv8wzlynspw13r9lrpn"
   },
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def utility_score(date, weight, resp, action):\n",
    "    pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(pi) / np.sqrt(np.sum(pi ** 2)) * np.sqrt(250 / len(pi))\n",
    "    return min(max(t, 0), 6) * np.sum(pi)\n",
    "\n",
    "def estimate_model(df, model):\n",
    "    expected_score = utility_score(\n",
    "        df[\"date\"].values,\n",
    "        df[\"weight\"].values,\n",
    "        df[\"resp\"].values,\n",
    "        df[\"action\"].values\n",
    "    )\n",
    "    actual_score = utility_score(\n",
    "        df[\"date\"].values,\n",
    "        df[\"weight\"].values,\n",
    "        df[\"resp\"].values,\n",
    "        (model.predict(df[features], prediction_type=\"RawFormulaVal\") > 0).astype(int)\n",
    "    )\n",
    "    print(int(expected_score), int(actual_score), round(actual_score / expected_score, 2))\n",
    "    \n",
    "def feature_importances(model, top_n=20):\n",
    "    values = sorted(list(zip(model.feature_names_, model.feature_importances_)), key=lambda x: -x[1])\n",
    "    for value in values[:top_n]:\n",
    "        print(value[0], \": \", str(round(value[1], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "23qjvnnz2p1sslb8os8379"
   },
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mfficxrfsda57fsipqij7n"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_data_path + \"train.csv\")\n",
    "df = df.astype({c: np.float32 for c in df.select_dtypes(include=\"float64\").columns})\n",
    "df[\"action\"] = (df[\"resp\"] > 0).astype(int)\n",
    "\n",
    "features_info = pd.read_csv(input_data_path + \"features.csv\")\n",
    "features_info.set_index(keys=[\"feature\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "422axp6sncgt4g88b7x6w"
   },
   "source": [
    "#### Fill nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qgfdlsoo9h7w61paq1fvn"
   },
   "outputs": [],
   "source": [
    "def fillna_mean(df):\n",
    "    features_mean = df[features].mean()\n",
    "    df[features] = df[features].fillna(features_mean)\n",
    "    with open(prepared_data_path + \"features_mean.pkl\", \"wb\") as f:\n",
    "        pickle.dump(features_mean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jnjpp98ivlflw88fk4qsj"
   },
   "outputs": [],
   "source": [
    "def fillna_ffill(df):\n",
    "    df[features] = df[features].fillna(method = \"ffill\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "90z64q083eagln57rb5su"
   },
   "outputs": [],
   "source": [
    "def fillna_mean_by_feature_0(df):\n",
    "    features_mean = df[features].groupby(\"feature_0\").mean()\n",
    "    features_mean[\"feature_0\"] = features_mean.index\n",
    "    df.sort_values(by=\"feature_0\", inplace=True)\n",
    "    df[features] = pd.concat([\n",
    "        df[df[\"feature_0\"] == -1][features].fillna(features_mean.loc[-1]),\n",
    "        df[df[\"feature_0\"] == 1][features].fillna(features_mean.loc[1])\n",
    "    ])\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    with open(output_data_path + \"features_mean.pkl\", \"wb\") as f:\n",
    "        pickle.dump(features_mean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "6bmwkg795e93xd162opb6x"
   },
   "outputs": [],
   "source": [
    "fillna_mean_by_feature_0(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "sipnehvddlc5oea5ywtrvs"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ui3xlvplrxcm2eyz613ik"
   },
   "outputs": [],
   "source": [
    "date_to_index = {}\n",
    "dates = list(set(df[\"date\"].values))\n",
    "np.random.shuffle(dates)\n",
    "for i, date in enumerate(dates):\n",
    "    date_to_index[date] = i\n",
    "df[\"order_id\"] = df[\"date\"].apply(lambda x: date_to_index[x])\n",
    "df.sort_values(by=[\"order_id\", \"ts_id\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "958pqdsm5pngrwsiufws29"
   },
   "outputs": [],
   "source": [
    "df_train = df[df[\"date\"] < 400]\n",
    "df_val = df[df[\"date\"] >= 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "p5e4iuqg0kgfaghj5jown8"
   },
   "source": [
    "### Catboost with random train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "n7ym56b4zed6obnjnb5yk3"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_train, test_size=0.2, random_state=random_state)\n",
    "model = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    custom_metric=[\"Precision\", \"Recall\", \"F1\"],\n",
    "    iterations=1000,\n",
    "    learning_rate=None,\n",
    "    random_seed=random_state,\n",
    "    l2_leaf_reg=3,\n",
    "    use_best_model=True,\n",
    "    depth=4,\n",
    "    auto_class_weights=\"Balanced\",\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=100,\n",
    "    task_type=\"GPU\" if tf.test.is_gpu_available() else \"CPU\",\n",
    "    metric_period=250,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X=Pool(\n",
    "        data=train[features],\n",
    "        label=train[\"action\"],\n",
    "        weight=train[\"weight\"] + 1\n",
    "    ),\n",
    "    eval_set=Pool(\n",
    "        data=test[features],\n",
    "        label=test[\"action\"],\n",
    "        weight=test[\"weight\"] + 1\n",
    "    )\n",
    ")\n",
    "estimate_model(df_train, model)\n",
    "estimate_model(df_val, model)\n",
    "estimate_model(df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "p0r6vegycbux27h2drre"
   },
   "outputs": [],
   "source": [
    "model.save_model(prepared_data_path + \"model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8pqwhx445u8tpd2230as8"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=random_state)\n",
    "for train_idx, test_idx in gss.split(X=df_train[\"order_id\"].values, groups=df_train[\"order_id\"].values):\n",
    "    model = catboost_model()\n",
    "    \n",
    "    model.fit(\n",
    "        X=Pool(\n",
    "            data=df_train.iloc[train_idx][features],\n",
    "            label=df_train.iloc[train_idx][\"action\"],\n",
    "            #weight=df.iloc[train_idx][\"weight\"] + 1,\n",
    "            #group_id=df_train.iloc[train_idx][\"date\"],\n",
    "        ),\n",
    "        eval_set=Pool(\n",
    "            data=df_train.iloc[test_idx][features],\n",
    "            label=df_train.iloc[test_idx][\"action\"],\n",
    "            #weight=df.iloc[test_idx][\"weight\"] + 1,\n",
    "            #group_id=df_train.iloc[test_idx][\"date\"],\n",
    "        )\n",
    "    )\n",
    "    estimate_model(df_train.iloc[test_idx], model)\n",
    "    models.append(model)\n",
    "\n",
    "model = sum_models(models)\n",
    "estimate_model(df_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kx8ee7bathbd5wibmngsq"
   },
   "outputs": [],
   "source": [
    "model = catboost_model(use_best_model=False)\n",
    "model.fit(\n",
    "    X=Pool(\n",
    "        data=df_train[features],\n",
    "        label=df_train[\"action\"],\n",
    "        weight=df_train[\"weight\"] + 1,\n",
    "        group_id=df_train[\"date\"],\n",
    "    )\n",
    ")\n",
    "estimate_model(df_val, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notebookId": "8766bdf2-c6f6-4695-98e2-3af663e5fd96"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
